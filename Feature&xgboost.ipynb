{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import time\n",
    "import matplotlib as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kaijiang/anaconda/lib/python3.6/site-packages/IPython/core/interactiveshell.py:2717: DtypeWarning: Columns (22,32,34,49,55) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "sample_submission = pd.read_csv('sample_submission.csv')\n",
    "train_data = pd.read_csv('train_2016_v2.csv')\n",
    "properties_data= pd.read_csv('properties_2016.csv')\n",
    "zillow_dict = pd.read_excel('zillow_data_dictionary.xlsx', sheetname=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "con_columns = []\n",
    "cat_columns = []\n",
    "text_columns = []\n",
    "id=['parcelid']\n",
    "\n",
    "\n",
    "for i in range(len(zillow_dict['Data Dictionary'].variable)):\n",
    "    if zillow_dict['Data Dictionary'].variable[i]=='con':\n",
    "        con_columns.append(zillow_dict['Data Dictionary'].Feature[i].replace(\"'\",\"\"))\n",
    "    if zillow_dict['Data Dictionary'].variable[i]=='cat':\n",
    "        cat_columns.append(zillow_dict['Data Dictionary'].Feature[i].replace(\"'\",\"\"))\n",
    "    if zillow_dict['Data Dictionary'].variable[i]=='text':\n",
    "        text_columns.append(zillow_dict['Data Dictionary'].Feature[i].replace(\"'\",\"\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# then read the rule and join to get full data, then use simple random forest to get predicted results, \n",
    "# results same for all time points\n",
    "groundtruth = train_data.merge(properties_data,right_on='parcelid',left_on='parcelid', how='left')\n",
    "full_data = train_data.merge(properties_data,right_on='parcelid',left_on='parcelid', how='right')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "full_data = full_data.replace(np.nan, -1)\n",
    "full_data['taxdelinquencyflag']=full_data['taxdelinquencyflag'].replace('Y', 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "airconditioningtypeid\n",
      "{1.0: 1, -1.0: 0, 5.0: 3, 13.0: 7, 11.0: 5, 9.0: 4, 3.0: 2, 12.0: 6}\n",
      "architecturalstyletypeid\n",
      "{-1.0: 0, 7.0: 4, 8.0: 5, 2.0: 1, 10.0: 6, 3.0: 2, 21.0: 7, 5.0: 3, 27.0: 8}\n",
      "buildingclasstypeid\n",
      "{-1.0: 0, 4.0: 4, 3.0: 3, 5.0: 5, 2.0: 2, 1.0: 1}\n",
      "decktypeid\n",
      "{-1.0: 0, 66.0: 1}\n",
      "fireplaceflag\n",
      "{-1: 0, True: 1}\n"
     ]
    }
   ],
   "source": [
    "from sklearn import preprocessing\n",
    "for i in cat_columns:\n",
    "    \n",
    "    le = preprocessing.LabelEncoder()\n",
    "    le.fit(full_data[i])\n",
    "    labels = dict(zip(full_data[i].unique()\n",
    "               , le.transform(full_data[i].unique())))\n",
    "    print(i)\n",
    "    print(labels)\n",
    "    #print(le.classes_)\n",
    "    full_data[i]=le.transform(full_data[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "OHE = preprocessing.OneHotEncoder()\n",
    "full_data_ohe=OHE.fit_transform(full_data[cat_columns])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "SSL = preprocessing.StandardScaler()\n",
    "for num_col in con_columns:\n",
    "    full_data[num_col] = SSL.fit_transform(full_data[num_col])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from scipy.stats import skew, boxcox\n",
    "for i in con_columns:\n",
    "    \n",
    "    full_data[i], _ = boxcox(full_data[i]+20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import grid_search, metrics\n",
    "\n",
    "#scorer = metrics.make_scorer('ndcg_scorer', needs_proba=True) \n",
    "# 如果你要customize scorer\n",
    "\n",
    "def search_model(train_x, train_y, est, param_grid, n_jobs, cv, refit=False):\n",
    "##Grid Search for the best model\n",
    "    model = grid_search.GridSearchCV(estimator  = est,\n",
    "                                     param_grid = param_grid,\n",
    "                                     scoring = 'neg_mean_absolute_error',\n",
    "                                     verbose  = 1,\n",
    "                                     n_jobs  = n_jobs,\n",
    "                                     iid    = True,\n",
    "                                     refit    = refit,\n",
    "                                     cv      = cv)\n",
    "    # Fit Grid Search Model\n",
    "    model.fit(train_x, train_y)\n",
    "    print(\"Best score: %0.3f\" % model.best_score_)\n",
    "    print(\"Best parameters set:\", model.best_params_)\n",
    "    print(\"Scores:\", model.grid_scores_)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "param_grid = {\n",
    "              'learning_rate':[0.02],\n",
    "              'n_estimators':[500],\n",
    "              'max_depth': [9],\n",
    "              'min_child_weight':[50],\n",
    "              'subsample': [0.78],\n",
    "              'colsample_bytree':[0.67],\n",
    "              'gamma':[0.9],\n",
    "              'nthread': [-1],\n",
    "              'seed' : [1234]}\n",
    "\n",
    "model = search_model(X_train,\n",
    "                     y_train,\n",
    "                     xgb.XGBRegressor(),\n",
    "                     param_grid,\n",
    "                     n_jobs = 1,\n",
    "                     cv = 4,\n",
    "                     refit = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_predict = linear_reg.predict(X_test)\n",
    "metrics.mean_absolute_error(y_test, y_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# in this way we get a baseline xgboost model score"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
